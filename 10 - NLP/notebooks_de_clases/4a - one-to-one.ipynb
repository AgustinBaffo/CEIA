{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4a - one-to-one.ipynb","provenance":[{"file_id":"1H2TBQiYfga9Z-2YTGSGgqECYau8br-yB","timestamp":1648472756352}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NEnBiuLcukJc"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## RNN one-to-one"]},{"cell_type":"markdown","metadata":{"id":"i96B2RF8uqEb"},"source":["#### Datos\n","El objecto es utilizar una serie de sucuencias númericas (datos sintéticos) para poner a prueba el uso de las redes RNN. Este ejemplo se inspiró en otro artículo, lo tienen como referencia en el siguiente link:\\\n","[LINK](https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras/)"]},{"cell_type":"code","metadata":{"id":"Lx0HQ-1RvJw9"},"source":["import re\n","\n","import numpy as np\n","import pandas as pd\n","\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers.core import Activation, Dropout, Dense\n","from keras.layers import Flatten, LSTM, SimpleRNN\n","from keras.models import Model\n","from keras.layers.embeddings import Embedding\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.layers import Input\n","from keras.layers.merge import Concatenate\n","from keras.layers import Bidirectional"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"10bFkG1YuaD9"},"source":["# Generar datos sintéticos\n","X = list()\n","y = list()\n","X = [x+1 for x in range(20)]\n","\n","# \"y\" (target) se obtiene como cada dato de entrada multiplicado por 15\n","y = [x * 15 for x in X]\n","\n","print(\"datos X:\", X)\n","print(\"datos y:\", y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oqabd-kYvza9"},"source":["# Cada dato X lo transformarmos en una matriz de 1 fila 1 columna (1x1)\n","X = np.array(X).reshape(len(X), 1, 1)\n","print(\"datos X:\", X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gYz6XpuyxBbQ"},"source":["y = np.asanyarray(y)\n","y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VG3-d_NXwDGD"},"source":["### 2 - Entrenar el modelo (RNN y LSTM)"]},{"cell_type":"code","metadata":{"id":"OFeZEc63wOvJ"},"source":["input_shape = X[0].shape\n","input_shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZir-NqDwWEo"},"source":["output_shape = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAhw8O9mwLR0"},"source":["# Comenzamos con una RNN clásica\n","# En general una celda RNN clásica ya no se utiliza, es solo a modo de ejemplo\n","model = Sequential()\n","model.add(SimpleRNN(64, activation='relu', input_shape=input_shape))\n","model.add(Dense(output_shape))\n","model.compile(loss='mse',\n","              optimizer=\"Adam\")\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSX93pkow2zM"},"source":["hist = model.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"anuBmCv0xNGA"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Entrenamiento\n","epoch_count = range(1, len(hist.history['loss']) + 1)\n","sns.lineplot(x=epoch_count,  y=hist.history['loss'], label='train')\n","sns.lineplot(x=epoch_count,  y=hist.history['val_loss'], label='valid')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HK9QLOCN2Vt0"},"source":["y_hat = model.predict(test_input, verbose=0)\n","y_hat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5g-FIt5d2ZSU"},"source":["15*30"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"88tdVCOyxcuy"},"source":["# Ensayo\n","# x = 30\n","# y_test = x * 15\n","\n","x_test = 30\n","y_test = x_test * 15\n","test_input = np.array([x_test])\n","test_input = test_input.reshape((1, 1, 1))\n","y_hat = model.predict(test_input, verbose=0)[0][0]\n","\n","print(\"y_test:\", y_test)\n","print(\"y_hat:\", y_hat)\n","\n","model.evaluate(test_input, np.array([y_test]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0-pi5qmVxav"},"source":["# Ahora probaremos con LSTM, qué es más compleja y por lo tanto\n","# requiere más parámetros a entrenar\n","model2 = Sequential()\n","model2.add(LSTM(64, activation='relu', input_shape=input_shape))\n","model2.add(Dense(output_shape))\n","model2.compile(loss='mse',\n","              optimizer=\"Adam\")\n","model2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bp5r9gUEWLVf"},"source":["hist2 = model2.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HNyQ__9fWUPC"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Entrenamiento\n","epoch_count = range(1, len(hist2.history['loss']) + 1)\n","sns.lineplot(x=epoch_count,  y=hist2.history['loss'], label='train')\n","sns.lineplot(x=epoch_count,  y=hist2.history['val_loss'], label='valid')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuCV-UBhWNb3"},"source":["# Ensayo\n","# x = 30\n","# y_test = x * 15\n","\n","x_test = 30\n","y_test = x_test * 15\n","test_input = np.array([x_test])\n","test_input = test_input.reshape((1, 1, 1))\n","y_hat = model2.predict(test_input, verbose=0)[0][0]\n","\n","print(\"y_test:\", y_test)\n","print(\"y_hat:\", y_hat)\n","\n","model2.evaluate(test_input, np.array([y_test]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DEI5TjSFWeY8"},"source":["Se puede observar que para un problema tan simple como este no hay mucha diferencia entre utilizar una RNN o LSTM."]},{"cell_type":"markdown","metadata":{"id":"AT8b9EfGyshD"},"source":["### 3 - Multi-layer LSTM"]},{"cell_type":"code","metadata":{"id":"cH8Yd6WYyzQQ"},"source":["# En esta oportunidad se utilizarán dos layer LSTM. Para poder conectar\n","# la primera layer con la segunda se debe colocar return_sequences=True\n","\n","model3 = Sequential()\n","model3.add(LSTM(64, activation='relu', return_sequences=True, input_shape=input_shape))\n","model3.add(LSTM(64, activation='relu'))\n","model3.add(Dense(output_shape))\n","model3.compile(loss='mse',\n","              optimizer=\"Adam\")\n","\n","model3.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLtlpYpxzQZr"},"source":["hist3 = model3.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3Sl3cUJzZV_"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Entrenamiento\n","epoch_count = range(1, len(hist3.history['loss']) + 1)\n","sns.lineplot(x=epoch_count,  y=hist3.history['loss'], label='train')\n","sns.lineplot(x=epoch_count,  y=hist3.history['val_loss'], label='valid')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FveVOv2xzfkC"},"source":["# Ensayo\n","# x = 30\n","# y_test = x * 15\n","\n","x_test = 30\n","y_test = x_test * 15\n","test_input = np.array([x_test])\n","test_input = test_input.reshape((1, 1, 1))\n","y_hat = model3.predict(test_input, verbose=0)[0][0]\n","\n","print(\"y_test:\", y_test)\n","print(\"y_hat:\", y_hat)\n","\n","model3.evaluate(test_input, np.array([y_test]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zd1g5MZfz5qB"},"source":["### 4 - Conclusión\n","Implementar un modelo basado en RNN o LSTM es muy sensillo, hay que tener en cuenta que al apilar varias layers hay que colocar el flag \"return_sequence\" en \"True\".\n","El resultado alcanzado es bueno pero podría mejorarse agregando más layer LSTM o más layer Densas"]}]}