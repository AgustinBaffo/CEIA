{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4b - one-to-many.ipynb","provenance":[{"file_id":"1hqz_5ngXD4Zrv2E4rp354GmqfRYou0ZW","timestamp":1648472822167}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NEnBiuLcukJc"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## RNN one-to-many"]},{"cell_type":"markdown","metadata":{"id":"i96B2RF8uqEb"},"source":["#### Datos\n","El objecto es utilizar una serie de sucuencias númericas (datos sintéticos) para poner a prueba el uso de las redes RNN. Este ejemplo se inspiró en otro artículo, lo tienen como referencia en el siguiente link:\\\n","[LINK](https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras-part-2/)"]},{"cell_type":"code","metadata":{"id":"Lx0HQ-1RvJw9"},"source":["import re\n","\n","import numpy as np\n","import pandas as pd\n","\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers.core import Activation, Dropout, Dense\n","from keras.layers import Flatten, LSTM\n","from keras.layers import GlobalMaxPooling1D\n","from keras.models import Model\n","from keras.layers.embeddings import Embedding\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.layers import Input\n","from keras.layers.merge import Concatenate\n","from keras.layers import Bidirectional"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"10bFkG1YuaD9"},"source":["# Generar datos sintéticos\n","X = list()\n","y = list()\n","\n","# X es una lista de números de 1 al 43 que avanzan de 3 en 3\n","X = [x for x in range(1, 44, 3)]\n","\n","# \"y\" (target) se obtiene como por cada dato de entrada se\n","# se obtienen dos datos de salida como x+1 y x+2\n","y = [ [x+1, x+2] for x in X]\n","\n","print(\"datos X:\", X)\n","print(\"datos y:\", y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oqabd-kYvza9"},"source":["# Cada dato X lo transformarmos en una matriz de 1 fila 1 columna (1x1)\n","X = np.array(X).reshape(len(X), 1, 1)\n","print(\"datos X:\", X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gYz6XpuyxBbQ"},"source":["y = np.asanyarray(y)\n","y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VG3-d_NXwDGD"},"source":["### 2 - Entrenar el modelo"]},{"cell_type":"code","metadata":{"id":"OFeZEc63wOvJ"},"source":["input_shape = X[0].shape\n","input_shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZir-NqDwWEo"},"source":["output_shape = y.shape[1]\n","output_shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAhw8O9mwLR0"},"source":["model = Sequential()\n","model.add(LSTM(64, activation='relu', input_shape=input_shape))\n","model.add(Dense(output_shape))\n","model.compile(loss='mse',\n","              optimizer=\"Adam\")\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSX93pkow2zM"},"source":["hist = model.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"anuBmCv0xNGA"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Entrenamiento\n","epoch_count = range(1, len(hist.history['loss']) + 1)\n","sns.lineplot(x=epoch_count,  y=hist.history['loss'], label='train')\n","sns.lineplot(x=epoch_count,  y=hist.history['val_loss'], label='valid')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"88tdVCOyxcuy"},"source":["# Ensayo\n","x_test = 10\n","y_test = [x_test + 1, x_test + 2]\n","test_input = np.array([x_test])\n","test_input = test_input.reshape((1, 1, 1))\n","y_hat = model.predict(test_input, verbose=0)[0]\n","\n","print(\"y_test:\", y_test)\n","print(\"y_hat:\", y_hat)\n","\n","model.evaluate(test_input, np.array([y_test]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AT8b9EfGyshD"},"source":["### 3 - Multi-layer RNN"]},{"cell_type":"code","metadata":{"id":"cH8Yd6WYyzQQ"},"source":["# En esta oportunidad se utilizarán dos layer LSTM. Para poder conectar\n","# la primera layer con la segunda se debe colocar return_sequences=True\n","\n","model2 = Sequential()\n","model2.add(LSTM(64, activation='relu', return_sequences=True, input_shape=input_shape))\n","model2.add(LSTM(64, activation='relu'))\n","model2.add(Dense(output_shape))\n","model2.compile(loss='mse',\n","              optimizer=\"Adam\")\n","\n","model2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLtlpYpxzQZr"},"source":["hist2 = model2.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3Sl3cUJzZV_"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Entrenamiento\n","epoch_count = range(1, len(hist2.history['loss']) + 1)\n","sns.lineplot(x=epoch_count,  y=hist2.history['loss'], label='train')\n","sns.lineplot(x=epoch_count,  y=hist2.history['val_loss'], label='valid')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FveVOv2xzfkC"},"source":["# Ensayo\n","x_test = 10\n","y_test = [x_test + 1, x_test + 2]\n","test_input = np.array([x_test])\n","test_input = test_input.reshape((1, 1, 1))\n","y_hat = model2.predict(test_input, verbose=0)[0]\n","\n","print(\"y_test:\", y_test)\n","print(\"y_hat:\", y_hat)\n","\n","model2.evaluate(test_input, np.array([y_test]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zd1g5MZfz5qB"},"source":["### 4 - Conclusión\n","La unica diferencia que se debe tener en cuenta cuando hay más de una salida es que la cantidad de neuronas de la última capa debe coincidir con el tamaño de la secuencia de salida.\n","En este ejemplo, donde el problema es más complejo, hubo una diferencia apreciable entre utilizar una sola capa o varias LSTM."]}]}