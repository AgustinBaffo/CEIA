{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Train-Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalization\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Classification models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_processed = pd.read_pickle('./data/df_train_processed.pkl')\n",
    "\n",
    "open_file = open('./data/param_dict.pkl', \"rb\")\n",
    "param_dict = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "df_test_processed = pd.read_pickle('./data/df_test_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df_train_processed.drop(['RainTomorrow','RainfallTomorrow'],axis=1)\n",
    "# y_train = df_train_processed.RainTomorrow\n",
    "\n",
    "# X_test = df_test_processed.drop(['RainTomorrow','RainfallTomorrow'],axis=1)\n",
    "# y_test = df_test_processed.RainTomorrow\n",
    "\n",
    "# Split into train/cv\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(\n",
    "    df_train_processed.drop(['RainTomorrow','RainfallTomorrow'], axis=1),\n",
    "    df_train_processed['RainTomorrow'],\n",
    "    test_size=0.1,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y,pred):\n",
    "    print(\"accuracy = \"+str(metrics.accuracy_score(y, pred)))\n",
    "    print(\"precision = \"+str(metrics.precision_score(y, pred)))\n",
    "    print(\"recall = \"+str(metrics.recall_score(y, pred)))\n",
    "    print(\"f1_score = \"+str(metrics.f1_score(y, pred)))\n",
    "    print(\"\\nconfusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y, pred))\n",
    "    # print(metrics.classification_report(y_cv, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components required to explain 0.95% of the variance = 15\n"
     ]
    }
   ],
   "source": [
    "explained_variance = .95\n",
    "pca = PCA(n_components=explained_variance).fit(X_train)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_cv_pca = pca.transform(X_cv)\n",
    "\n",
    "# pca = PCA(n_components=explained_variance).fit(df_train_processed)\n",
    "# df_train_pca = pca.transform(df_train_processed)\n",
    "\n",
    "print(\"Number of components required to explain \"+str(explained_variance)+\"% of the variance = \"+str(X_train_pca.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection: RFE (with simple Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns selected: ['Rainfall', 'WindGustSpeed', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'RainToday', 'LocationType_0', 'LocationType_2', 'LocationType_3', 'LocationType_4', 'PressureMean', 'TempMaxDiff', 'imputed_mean', 'WindDir9am_sin', 'WindDir3pm_sin']\n"
     ]
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "rfe = RFE(estimator=logisticRegr, step=1, verbose=0, n_features_to_select=15)\n",
    "rfe = rfe.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "total_cols = np.array(X_train.columns.values.tolist())\n",
    "selected_cols = total_cols[rfe.support_].tolist()\n",
    "X_train_rfe = X_train[selected_cols]\n",
    "X_cv_rfe =  X_cv[selected_cols]\n",
    "print(\"Columns selected: \"+str(selected_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(clf_,grid_values_,X_train_,y_train_,X_cv_,y_cv_,scoring_='recall',verbose_=0):\n",
    "    # model.get_params() # Return selected params\n",
    "    # cv=None -> None, to use the default 5-fold cross validation (K-Fold, k=5)\n",
    "    model_ = GridSearchCV(clf_, param_grid = grid_values_, cv=None, scoring=scoring_,verbose=verbose_)\n",
    "    model_.fit(X_train_, y_train_)\n",
    "\n",
    "    y_pred = model_.predict(X_cv_)\n",
    "    metrics_={    \n",
    "        \"accuracy\":         metrics.accuracy_score(y_cv_, y_pred),\n",
    "        \"precision\":        metrics.precision_score(y_cv_, y_pred),\n",
    "        \"recall\":           metrics.recall_score(y_cv_, y_pred),\n",
    "        \"f1_score\":         metrics.f1_score(y_cv_, y_pred),\n",
    "        \"confusion_matrix\": metrics.confusion_matrix(y_cv_, y_pred)\n",
    "    }\n",
    "    return model_, metrics_\n",
    "\n",
    "def train_models(X_train_, y_train_, X_cv_, y_cv_, features_selection=''):\n",
    "    model_list=[]\n",
    "\n",
    "    # Dummy Classifier\n",
    "    clf = DummyClassifier(strategy= 'most_frequent')\n",
    "    grid_values={}\n",
    "    model, model_metrics = testModel(clf,grid_values,X_train_,y_train_,X_cv_,y_cv_)\n",
    "    model_list.append(\n",
    "        {'name': 'DummyClassifier',\n",
    "        'model': model,\n",
    "        'features_selection': features_selection,\n",
    "        'metrics': model_metrics\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # LogisticRegression\n",
    "    clf = LogisticRegression(class_weight='balanced')\n",
    "    grid_values = {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'C': [0.001,0.01,.09,1,5,10,25],\n",
    "        'l1_ratio': [.25,.5,.75]\n",
    "        }\n",
    "\n",
    "    model, model_metrics = testModel(clf,grid_values,X_train_,y_train_,X_cv_,y_cv_)\n",
    "    model_list.append(\n",
    "        {'name': 'LogisticRegression',\n",
    "        'model': model,\n",
    "        'features_selection': features_selection,\n",
    "        'metrics': model_metrics  \n",
    "        }\n",
    "    )\n",
    "\n",
    "    # SGDClassifier\n",
    "    loss_list = [\n",
    "        'hinge',            # SVM\n",
    "        'log',              # Logistic Regression\n",
    "        'modified_huber',   # Probabilistic classifier (smooth loss)\n",
    "        'squared_hinge',    # Like hinge but quadratically penalized\n",
    "    ]\n",
    "\n",
    "    for loss in loss_list:\n",
    "        grid_values = {\n",
    "            'l1_ratio': [0,0.25,0.5,0.751], # (0 <= l1_ratio <= 1): l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1\n",
    "            'alpha': [0.0001,0.001,0.01,0.1,1,10], # The higher the value, the stronger the regularization. Also used to compute the learning rate when set to learning_rate is set to ‘optimal’.\n",
    "            'eta0': [0.001,0.1,1] # Initial learning rate\n",
    "            }\n",
    "\n",
    "        clf = SGDClassifier(class_weight='balanced', verbose=0, max_iter=1000, tol=1e-3, penalty='elasticnet',\n",
    "                            learning_rate='optimal', early_stopping=True, validation_fraction=0.1, \n",
    "                            n_iter_no_change=5, loss=loss)\n",
    "\n",
    "        model, model_metrics = testModel(clf,grid_values,X_train_,y_train_,X_cv_,y_cv_)\n",
    "        model_list.append(\n",
    "            {'name': 'SGDClassifier_'+str(loss),\n",
    "            'model': model,\n",
    "            'features_selection': features_selection,\n",
    "            'metrics': model_metrics    \n",
    "            }\n",
    "        )\n",
    "\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_rfe = train_models(X_train_rfe, y_train, X_cv_rfe, y_cv, features_selection='RFE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_pca = train_models(X_train_pca, y_train, X_cv_pca, y_cv, features_selection='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = model_list_pca+model_list_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier | Features selection: PCA\n",
      "\t- Accuracy = 0.8297569312571211\n",
      "\t- Precision = 0.0\n",
      "\t- Recall = 0.0\n",
      "\t- f1_score = 0.0\n",
      "\n",
      "LogisticRegression | Features selection: PCA\n",
      "\t- Accuracy = 0.7513292821876187\n",
      "\t- Precision = 0.3788145539906103\n",
      "\t- Recall = 0.7200223089793641\n",
      "\t- f1_score = 0.49644299173235906\n",
      "\n",
      "SGDClassifier_hinge | Features selection: PCA\n",
      "\t- Accuracy = 0.6119445499430307\n",
      "\t- Precision = 0.2735886300829056\n",
      "\t- Recall = 0.7730061349693251\n",
      "\t- f1_score = 0.4041405452689896\n",
      "\n",
      "SGDClassifier_log | Features selection: PCA\n",
      "\t- Accuracy = 0.6419483478921383\n",
      "\t- Precision = 0.29708658186294623\n",
      "\t- Recall = 0.807585052983826\n",
      "\t- f1_score = 0.4343782810859457\n",
      "\n",
      "SGDClassifier_modified_huber | Features selection: PCA\n",
      "\t- Accuracy = 0.7409798708697304\n",
      "\t- Precision = 0.36600745199197476\n",
      "\t- Recall = 0.7122141662018963\n",
      "\t- f1_score = 0.4835289663006437\n",
      "\n",
      "SGDClassifier_squared_hinge | Features selection: PCA\n",
      "\t- Accuracy = 0.8297569312571211\n",
      "\t- Precision = 0.0\n",
      "\t- Recall = 0.0\n",
      "\t- f1_score = 0.0\n",
      "\n",
      "DummyClassifier | Features selection: RFE\n",
      "\t- Accuracy = 0.8297569312571211\n",
      "\t- Precision = 0.0\n",
      "\t- Recall = 0.0\n",
      "\t- f1_score = 0.0\n",
      "\n",
      "LogisticRegression | Features selection: RFE\n",
      "\t- Accuracy = 0.7542726927459172\n",
      "\t- Precision = 0.3818722139673105\n",
      "\t- Recall = 0.716675962074735\n",
      "\t- f1_score = 0.4982551376502521\n",
      "\n",
      "SGDClassifier_hinge | Features selection: RFE\n",
      "\t- Accuracy = 0.5220281048233953\n",
      "\t- Precision = 0.24500393391030684\n",
      "\t- Recall = 0.8683770217512549\n",
      "\t- f1_score = 0.38217967599410896\n",
      "\n",
      "SGDClassifier_log | Features selection: RFE\n",
      "\t- Accuracy = 0.17024306874287884\n",
      "\t- Precision = 0.17024306874287884\n",
      "\t- Recall = 1.0\n",
      "\t- f1_score = 0.29095334685598373\n",
      "\n",
      "SGDClassifier_modified_huber | Features selection: RFE\n",
      "\t- Accuracy = 0.682016710976073\n",
      "\t- Precision = 0.30685203574975173\n",
      "\t- Recall = 0.6893474623535973\n",
      "\t- f1_score = 0.4246693008074214\n",
      "\n",
      "SGDClassifier_squared_hinge | Features selection: RFE\n",
      "\t- Accuracy = 0.7042347132548424\n",
      "\t- Precision = 0.27996005326231693\n",
      "\t- Recall = 0.4690462911321807\n",
      "\t- f1_score = 0.3506358140504482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in model_list:\n",
    "    print(str(m['name'])+\" | Features selection: \"+str(m['features_selection'])+ \\\n",
    "    \"\\n\\t- Accuracy = \"+str(m['metrics']['accuracy'])+\"\\n\\t- Precision = \"+str(m['metrics']['precision'])+ \\\n",
    "    \"\\n\\t- Recall = \"+str(m['metrics']['recall'])+\"\\n\\t- f1_score = \"+str(m['metrics']['f1_score'])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "# open_file = open('./data/model_list.pkl', \"wb\")\n",
    "# pickle.dump(model_list, open_file)\n",
    "# open_file.close()\n",
    "\n",
    "# Load\n",
    "# open_file = open('./data/model_list.pkl', \"rb\")\n",
    "# model_list = pickle.load(open_file)\n",
    "# open_file.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
