{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Train-Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Normalization\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Classification models\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_skewed_boundaries(df, variable, distance=1.5):\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "    lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n",
    "    upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n",
    "    return upper_boundary, lower_boundary\n",
    "    \n",
    "def transform_outliers(df, norm_col, threshold_capped=1.5, threshold_trimmed=1.8,  test_mode=False, limits={},\n",
    "                        use_manual_limits=False, upper_limit_trim=0, lower_limit_trim=0, upper_limit_cap=0, lower_limit_cap=0, print_output=False):\n",
    "    \n",
    "    outliers_limits={}\n",
    "    # Trimming and capping outliers\n",
    "    outliers_total = np.array(np.repeat(False,df.shape[0]))\n",
    "    df_capped = df.copy()\n",
    "    for col in norm_col:\n",
    "        \n",
    "        if not test_mode:\n",
    "            outliers_limits_col={}\n",
    "            if use_manual_limits:\n",
    "                upper_limit, lower_limit = upper_limit_trim, lower_limit_trim\n",
    "            else:\n",
    "                upper_limit, lower_limit = find_skewed_boundaries(df, col, threshold_trimmed)\n",
    "\n",
    "            outliers_limits_col['upper_limit_trim'] = upper_limit\n",
    "            outliers_limits_col['lower_limit_trim'] = lower_limit\n",
    "        else:\n",
    "            upper_limit, lower_limit = limits[col]['upper_limit_trim'], limits[col]['lower_limit_trim']\n",
    "\n",
    "        outliers = np.where(df[col] > upper_limit, True,\n",
    "                            np.where(df[col] < lower_limit, True, False))                        \n",
    "        outliers_total = np.logical_or(outliers_total, outliers)\n",
    "        \n",
    "        if print_output:\n",
    "            print(str(col) + \" outliers = \"+str(outliers.sum()))\n",
    "        \n",
    "        if not test_mode:\n",
    "            if use_manual_limits:\n",
    "                upper_limit, lower_limit = upper_limit_cap, lower_limit_cap\n",
    "            else:\n",
    "                upper_limit, lower_limit = find_skewed_boundaries(df, col, threshold_capped)\n",
    "\n",
    "            outliers_limits_col['upper_limit_cap'] = upper_limit\n",
    "            outliers_limits_col['lower_limit_cap'] = lower_limit\n",
    "            outliers_limits[col] = outliers_limits_col\n",
    "        else:\n",
    "            upper_limit, lower_limit = limits[col]['upper_limit_cap'], limits[col]['lower_limit_cap']\n",
    "\n",
    "        df_capped[col] = np.where(df[col] > upper_limit, upper_limit,\n",
    "                            np.where(df[col] < lower_limit, lower_limit, df_capped[col]))\n",
    "\n",
    "    if print_output:\n",
    "        print(\"Total outliers = \"+str(outliers_total.sum()))\n",
    "        \n",
    "    df_trimmed = df_capped.loc[~(outliers_total)]\n",
    "    \n",
    "    if not test_mode:\n",
    "        return df_trimmed, outliers_limits\n",
    "    else:\n",
    "        return df_trimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple median imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_imputer(df,cols,test_mode=False,imputer_trained=None):\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "            \n",
    "    if not test_mode:\n",
    "        imputer = SimpleImputer(strategy='median',add_indicator=True) # Create imputer\n",
    "    else:\n",
    "        imputer = imputer_trained\n",
    "\n",
    "    X_imputed_median = imputer.fit_transform(df_imputed[cols]) # Fit-transform\n",
    "    imputed_median_cols = [str(d) + \"_imputed\" for d in cols]  # Name of indicators of imputation\n",
    "    median_cols = cols + imputed_median_cols\n",
    "\n",
    "    assert(not np.isnan(np.sum(X_imputed_median))) # Check not nan\n",
    "\n",
    "    # Replace in dataset\n",
    "    df_imputed.drop(cols,axis=1,inplace=True)\n",
    "    df_imputed[median_cols]=X_imputed_median\n",
    "    \n",
    "    if not test_mode:\n",
    "        return df_imputed, imputer\n",
    "    else:\n",
    "        return df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_imputer(df, cols, neighbors=5,test_mode=False,imputer_trained=None):\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    if not test_mode:            \n",
    "        imputer = KNNImputer(n_neighbors=neighbors,add_indicator=True)\n",
    "    else:\n",
    "        imputer = imputer_trained\n",
    "                  \n",
    "    X_imputed_knn = imputer.fit_transform(df_imputed[cols]) # Fit-transform\n",
    "    imputed_knn_cols = [str(d) + \"_imputed\" for d in cols]  # Name of indicators of imputation\n",
    "    knn_cols = cols + imputed_knn_cols\n",
    "\n",
    "    assert(not np.isnan(np.sum(X_imputed_knn))) # Check not nan\n",
    "\n",
    "    # Replace in dataset\n",
    "    df_imputed.drop(cols,axis=1,inplace=True)\n",
    "    print(\"knn_cols\")\n",
    "    print(knn_cols)\n",
    "    print(\"X_imputed_knn\")\n",
    "    print(X_imputed_knn)\n",
    "    df_imputed[knn_cols]=X_imputed_knn\n",
    "    \n",
    "    if not test_mode:\n",
    "        return df_imputed, imputer\n",
    "    else:\n",
    "        return df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape, X_test.shape = \n",
      "(2784, 9) (492, 9)\n",
      "% of Potability in original dataset: 39.010989010989015\n",
      "% of Potability in y_train: 39.008620689655174\n",
      "% of Potability in y_test: 39.02439024390244\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('water_potability.csv')\n",
    "df = df[df['Potability'].notna()]\n",
    "\n",
    "y = df['Potability']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['Potability'], axis=1),\n",
    "    y,\n",
    "    test_size=0.15,\n",
    "    random_state=0,\n",
    "    stratify=y\n",
    "    )\n",
    "    \n",
    "print(\"X_train.shape, X_test.shape = \")\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "print(\"% of Potability in original dataset: \"+str((df['Potability']==1).sum()/df.shape[0]*100))\n",
    "print(\"% of Potability in y_train: \"+str((y_train==1).sum()/y_train.shape[0]*100))\n",
    "print(\"% of Potability in y_test: \"+str((y_test==1).sum()/y_test.shape[0]*100))\n",
    "\n",
    "# Create df_train and df_test to process all columns together\n",
    "df_train = X_train.copy()\n",
    "df_train['Potability']=y_train\n",
    "\n",
    "df_test = X_test.copy()\n",
    "df_test['Potability']=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df(df, test_mode=False, param_dict={}):\n",
    "\n",
    "    if test_mode and not param_dict:\n",
    "        raise Exception('param_list need for test mode')\n",
    "\n",
    "    df_ = df.copy()\n",
    "\n",
    "    # Outliers\n",
    "    norm_col = [\n",
    "                'ph', \n",
    "                'Hardness', \n",
    "                'Solids', \n",
    "                'Chloramines',\n",
    "                'Sulfate', \n",
    "                'Conductivity',\n",
    "                'Organic_carbon', \n",
    "                'Trihalomethanes', \n",
    "                'Turbidity'\n",
    "            ]\n",
    "\n",
    "    if not test_mode:\n",
    "        df_, outliers_limits_ = transform_outliers(df_, norm_col)\n",
    "    else:\n",
    "        df_ = transform_outliers(df_, norm_col, test_mode=test_mode, limits=param_dict['outliers_limits'])\n",
    "    \n",
    "    # Scaling - General\n",
    "    scaled_columns = [\n",
    "                'ph', \n",
    "                'Hardness', \n",
    "                'Solids', \n",
    "                'Chloramines',\n",
    "                'Sulfate', \n",
    "                'Conductivity',\n",
    "                'Organic_carbon', \n",
    "                'Trihalomethanes', \n",
    "                'Turbidity'\n",
    "            ]\n",
    "\n",
    "    if not test_mode:\n",
    "        scaler_ = StandardScaler()\n",
    "        scaler_.fit(df_[scaled_columns])\n",
    "    else:\n",
    "        scaler_ = param_dict['scaler']\n",
    "        \n",
    "    df_[scaled_columns] = scaler_.transform(df_[scaled_columns])\n",
    "\n",
    "\n",
    "    # Imputation\n",
    "    imputed_by_median_col = ['Trihalomethanes']           \n",
    "    imputed_by_knn_col = ['ph','Sulfate']\n",
    "    neighbors_col =['Hardness','Solids','Chloramines','Conductivity','Organic_carbon','Trihalomethanes','Turbidity']\n",
    "\n",
    "    if not test_mode:\n",
    "        df_, median_imputer_list_ = median_imputer(df_,imputed_by_median_col)\n",
    "        df_, knn_imputer_list_ = knn_imputer(df_,imputed_by_knn_col+neighbors_col)\n",
    "    else:\n",
    "        df_ = median_imputer(df_, imputed_by_median_col, test_mode=test_mode, imputer_list=param_dict['median_imputer_list'])\n",
    "        df_ = knn_imputer(df_, imputed_by_knn_col+neighbors_col, test_mode=test_mode, imputer_list=param_dict['knn_imputer_list'])\n",
    "\n",
    "    # Normalization\n",
    "    norm_col_yj = [\n",
    "        'Hardness',\n",
    "        'Solids',\n",
    "        'Chloramines',\n",
    "        'Conductivity',\n",
    "        'Organic_carbon',\n",
    "        'Turbidity',\n",
    "        'Trihalomethanes',\n",
    "        'ph',\n",
    "        'Sulfate'\n",
    "    ]\n",
    "    \n",
    "    if not test_mode:\n",
    "        power_yj_ = PowerTransformer(method= 'yeo-johnson')\n",
    "        power_yj_.fit(df_[norm_col_yj])\n",
    "    else:\n",
    "        power_yj_ = param_dict['power_yj']\n",
    "                \n",
    "    df_[norm_col_yj] = power_yj_.transform(df_[norm_col_yj])\n",
    "\n",
    "    if not test_mode:\n",
    "        param_dict={'outliers_limits': outliers_limits_, \n",
    "                'scaler': scaler_, \n",
    "                'median_imputer_list': median_imputer_list_, \n",
    "                'knn_imputer_list': knn_imputer_list_, \n",
    "                'power_yj': power_yj_\n",
    "        }\n",
    "        return df_, param_dict\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_cols\n",
      "['ph', 'Sulfate', 'Hardness', 'Solids', 'Chloramines', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity', 'ph_imputed', 'Sulfate_imputed', 'Hardness_imputed', 'Solids_imputed', 'Chloramines_imputed', 'Conductivity_imputed', 'Organic_carbon_imputed', 'Trihalomethanes_imputed', 'Turbidity_imputed']\n",
      "X_imputed_knn\n",
      "[[-1.44716559  0.06084535  0.58154011 ... -0.6093051   0.\n",
      "   0.        ]\n",
      " [-0.04634461 -0.36217668  0.92591173 ... -0.38175869  0.\n",
      "   0.        ]\n",
      " [-1.01598802 -0.82867032  1.04724494 ... -2.41815014  0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.16777808 -1.32886599 -0.74263775 ...  0.27017033  1.\n",
      "   0.        ]\n",
      " [ 0.38839861  0.2886772   0.28679449 ... -0.32577933  0.\n",
      "   1.        ]\n",
      " [ 0.16828596  0.11451683 -0.46474853 ...  1.37207166  1.\n",
      "   1.        ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21703/3100472558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_process_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_process_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21703/177035619.py\u001b[0m in \u001b[0;36mpre_process_df\u001b[0;34m(df, test_mode, param_dict)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedian_imputer_list_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedian_imputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimputed_by_median_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mdf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_imputer_list_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_imputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimputed_by_knn_col\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mneighbors_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedian_imputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimputed_by_median_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimputer_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'median_imputer_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21703/1931328499.py\u001b[0m in \u001b[0;36mknn_imputer\u001b[0;34m(df, cols, neighbors, test_mode, imputer_trained)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_imputed_knn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_imputed_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdf_imputed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mknn_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_imputed_knn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3196\u001b[0m                 )[1]\n\u001b[1;32m   3197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3198\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0;31m# We have to operate column-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_2d_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0milocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlplane_indexer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_2d_value\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0milocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1733\u001b[0m                 \u001b[0;34m\"Must have equal len keys and value when setting with an ndarray\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "df_train_processed, param_dict = pre_process_df(df_train)\n",
    "df_test_processed = pre_process_df(df_test, test_mode=True, param_dict=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data into pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_processed.to_pickle('./data/df_train_processed.pkl')\n",
    "\n",
    "open_file = open('./data/df_param_dict.pkl', \"wb\")\n",
    "pickle.dump(param_dict, open_file)\n",
    "open_file.close()\n",
    "\n",
    "df_test_processed.to_pickle('./data/df_test_processed.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
